{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Скрипты для загрузки данных, обучения, кросс-валидации, загрузки предсказаний в файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from datetime import datetime\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engineering import reduce_mem_usage, add_rolling_features\n",
    "from feature_engineering import exponential_smoothing, signal_shifts\n",
    "from feature_engineering import batch_stats2, add_minus_signal\n",
    "from feature_engineering import delete_objects_after_rolling\n",
    "from feature_engineering import add_quantiles, add_target_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_df(df, window_sizes, alphas, shifts, batch_sizes):\n",
    "    df = reduce_mem_usage(df)\n",
    "    df = add_rolling_features(df, window_sizes)\n",
    "    df = reduce_mem_usage(df)\n",
    "    df = exponential_smoothing(df, alphas)\n",
    "    df = reduce_mem_usage(df)\n",
    "    df = signal_shifts(df, shifts)\n",
    "    df = reduce_mem_usage(df)\n",
    "    df = batch_stats2(df, batch_sizes)\n",
    "    df = reduce_mem_usage(df)\n",
    "    #df = add_minus_signal(df)\n",
    "    #df = reduce_mem_usage(df)\n",
    "    \n",
    "    if 'open_channels' in df.columns:\n",
    "        y = df['open_channels']\n",
    "        df = df.drop(columns=['time'])\n",
    "        return df, y\n",
    "    else:\n",
    "        df = df.drop(columns=['time'])\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 23.84 Mb (79.2% reduction)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4953467c092b4ab6bb98e3915cf60ab9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mem. usage decreased to 381.47 Mb (74.0% reduction)\n",
      "Mem. usage decreased to 410.08 Mb (17.3% reduction)\n",
      "Mem. usage decreased to 448.23 Mb (13.0% reduction)\n",
      "Mem. usage decreased to 762.94 Mb (55.3% reduction)\n",
      "Mem. usage decreased to  7.63 Mb (75.0% reduction)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02e437a234244fb798fbc43978d5118d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mem. usage decreased to 154.50 Mb (73.0% reduction)\n",
      "Mem. usage decreased to 165.94 Mb (17.1% reduction)\n",
      "Mem. usage decreased to 181.20 Mb (6.9% reduction)\n",
      "Mem. usage decreased to 307.08 Mb (55.2% reduction)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4636c4396cb44558bc6749a202322332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mem. usage decreased to 853.54 Mb (26.0% reduction)\n",
      "Mem. usage decreased to 343.32 Mb (25.9% reduction)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('data/train_clean.csv')\n",
    "test = pd.read_csv('data/test_clean.csv')\n",
    "\n",
    "window_sizes = [5, 100, 1000, 5000]\n",
    "alphas = [0.5, 0.2, 0.05]\n",
    "shifts = [1,-1,2,-2]\n",
    "batch_sizes = [50000, 25000, 2500]\n",
    "\n",
    "\n",
    "X_train, y_train = prepare_df(train, window_sizes, alphas, shifts, batch_sizes)\n",
    "X_test = prepare_df(test, window_sizes, alphas, shifts, batch_sizes)\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "add_quantiles(X_train, X_test, [3, 7, 15])\n",
    "add_target_encoding(X_train, X_test, [3, 7, 15])\n",
    "\n",
    "X_train = reduce_mem_usage(X_train)\n",
    "X_test = reduce_mem_usage(X_test)\n",
    "\n",
    "X_train = X_train.drop(columns=['open_channels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>signal</th>\n",
       "      <th>batch</th>\n",
       "      <th>rolling_mean_5</th>\n",
       "      <th>rolling_std_5</th>\n",
       "      <th>rolling_var_5</th>\n",
       "      <th>rolling_min_5</th>\n",
       "      <th>rolling_max_5</th>\n",
       "      <th>rolling_median_5</th>\n",
       "      <th>rolling_min_max_ratio_5</th>\n",
       "      <th>rolling_min_max_diff_5</th>\n",
       "      <th>...</th>\n",
       "      <th>quant_15</th>\n",
       "      <th>quant_3_mean</th>\n",
       "      <th>quant_3_std</th>\n",
       "      <th>quant_3_var</th>\n",
       "      <th>quant_7_mean</th>\n",
       "      <th>quant_7_std</th>\n",
       "      <th>quant_7_var</th>\n",
       "      <th>quant_15_mean</th>\n",
       "      <th>quant_15_std</th>\n",
       "      <th>quant_15_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-2.650391</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.265869</td>\n",
       "      <td>0.473633</td>\n",
       "      <td>0.224243</td>\n",
       "      <td>0.268311</td>\n",
       "      <td>0.482178</td>\n",
       "      <td>0.232544</td>\n",
       "      <td>0.003719</td>\n",
       "      <td>0.094666</td>\n",
       "      <td>0.008957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-2.849609</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.265869</td>\n",
       "      <td>0.473633</td>\n",
       "      <td>0.224243</td>\n",
       "      <td>0.014946</td>\n",
       "      <td>0.181030</td>\n",
       "      <td>0.032776</td>\n",
       "      <td>0.002825</td>\n",
       "      <td>0.079529</td>\n",
       "      <td>0.006321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-2.859375</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.265869</td>\n",
       "      <td>0.473633</td>\n",
       "      <td>0.224243</td>\n",
       "      <td>0.014946</td>\n",
       "      <td>0.181030</td>\n",
       "      <td>0.032776</td>\n",
       "      <td>0.002825</td>\n",
       "      <td>0.079529</td>\n",
       "      <td>0.006321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-2.435547</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.265869</td>\n",
       "      <td>0.473633</td>\n",
       "      <td>0.224243</td>\n",
       "      <td>0.268311</td>\n",
       "      <td>0.482178</td>\n",
       "      <td>0.232544</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.508789</td>\n",
       "      <td>0.258789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-2.615234</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.681641</td>\n",
       "      <td>0.177246</td>\n",
       "      <td>0.031433</td>\n",
       "      <td>-2.859375</td>\n",
       "      <td>-2.435547</td>\n",
       "      <td>-2.650391</td>\n",
       "      <td>1.174018</td>\n",
       "      <td>0.423828</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.265869</td>\n",
       "      <td>0.473633</td>\n",
       "      <td>0.224243</td>\n",
       "      <td>0.268311</td>\n",
       "      <td>0.482178</td>\n",
       "      <td>0.232544</td>\n",
       "      <td>0.003719</td>\n",
       "      <td>0.094666</td>\n",
       "      <td>0.008957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     signal  batch  rolling_mean_5  rolling_std_5  rolling_var_5  \\\n",
       "0 -2.650391      0        0.000000       0.000000       0.000000   \n",
       "1 -2.849609      0        0.000000       0.000000       0.000000   \n",
       "2 -2.859375      0        0.000000       0.000000       0.000000   \n",
       "3 -2.435547      0        0.000000       0.000000       0.000000   \n",
       "4 -2.615234      0       -2.681641       0.177246       0.031433   \n",
       "\n",
       "   rolling_min_5  rolling_max_5  rolling_median_5  rolling_min_max_ratio_5  \\\n",
       "0       0.000000       0.000000          0.000000                 0.000000   \n",
       "1       0.000000       0.000000          0.000000                 0.000000   \n",
       "2       0.000000       0.000000          0.000000                 0.000000   \n",
       "3       0.000000       0.000000          0.000000                 0.000000   \n",
       "4      -2.859375      -2.435547         -2.650391                 1.174018   \n",
       "\n",
       "   rolling_min_max_diff_5  ...  quant_15  quant_3_mean  quant_3_std  \\\n",
       "0                0.000000  ...         2      0.265869     0.473633   \n",
       "1                0.000000  ...         1      0.265869     0.473633   \n",
       "2                0.000000  ...         1      0.265869     0.473633   \n",
       "3                0.000000  ...         3      0.265869     0.473633   \n",
       "4                0.423828  ...         2      0.265869     0.473633   \n",
       "\n",
       "   quant_3_var  quant_7_mean  quant_7_std  quant_7_var  quant_15_mean  \\\n",
       "0     0.224243      0.268311     0.482178     0.232544       0.003719   \n",
       "1     0.224243      0.014946     0.181030     0.032776       0.002825   \n",
       "2     0.224243      0.014946     0.181030     0.032776       0.002825   \n",
       "3     0.224243      0.268311     0.482178     0.232544       0.281250   \n",
       "4     0.224243      0.268311     0.482178     0.232544       0.003719   \n",
       "\n",
       "   quant_15_std  quant_15_var  \n",
       "0      0.094666      0.008957  \n",
       "1      0.079529      0.006321  \n",
       "2      0.079529      0.006321  \n",
       "3      0.508789      0.258789  \n",
       "4      0.094666      0.008957  \n",
       "\n",
       "[5 rows x 90 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кастомная метрика для валидации xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MacroF1Metric(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    preds = np.round(np.clip(preds, 0, 10)).astype(int)\n",
    "    score = f1_score(labels, preds, average = 'macro')\n",
    "    return 'MacroF1Metric', score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение модели с разбиением на трейн и валидацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(X_train, y_train, params, num_iterations):\n",
    "    print('splitting...')\n",
    "    X_train_, X_valid, y_train_, y_valid = train_test_split(X_train, y_train, \n",
    "                                                            test_size=0.3,\n",
    "                                                            random_state=17)\n",
    "    \n",
    "    print('xgb matrix...')\n",
    "    train_set = xgb.DMatrix(X_train_, y_train_)\n",
    "    #val_set = xgb.DMatrix(X_valid, y_valid)\n",
    "    \n",
    "    del X_train_, y_train_\n",
    "    #del X_valid, y_valid\n",
    "    \n",
    "    print('training...')\n",
    "    model = xgb.train(params, train_set,\n",
    "                      num_boost_round=num_iterations)\n",
    "                      #evals=[(val_set, 'val')], \n",
    "                      #verbose_eval=1)\n",
    "                \n",
    "    prediction = model.predict(xgb.DMatrix(X_valid))\n",
    "    prediction = np.round(np.clip(prediction, 0, 10)).astype(int)\n",
    "    score = f1_score(y_valid, prediction, average = 'macro')\n",
    "    \n",
    "    print(f'score = {score}')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дообучение после каждой print_every итераций, сохраняем модель в файл, валидируемся, выводим скор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model_with_save(X_train, y_train, params, num_iterations, model_file):\n",
    "    print('splitting...')\n",
    "    X_train_, X_valid, y_train_, y_valid = train_test_split(X_train, y_train, \n",
    "                                                            test_size=0.3,\n",
    "                                                            random_state=17)\n",
    "    \n",
    "    print('xgb matrix...')\n",
    "    train_set = xgb.DMatrix(X_train_, y_train_)\n",
    "    val = xgb.DMatrix(X_valid)\n",
    "    \n",
    "    del X_train_, y_train_, X_valid\n",
    "    \n",
    "    print(datetime.now().strftime('%Y-%m-%d %H:%M:%S'), 'training...')\n",
    "    print_every = 15\n",
    "    \n",
    "    # первое обучение\n",
    "    model = xgb.train(params, train_set,\n",
    "                      num_boost_round=print_every)\n",
    "    model.save_model(model_file)\n",
    "    prediction = model.predict(val)\n",
    "    prediction = np.round(np.clip(prediction, 0, 10)).astype(int)\n",
    "    score = f1_score(y_valid, prediction, average = 'macro')\n",
    "    print(datetime.now().strftime('%Y-%m-%d %H:%M:%S'), '; ', \n",
    "          f'score = {score}', ';', f'iter = {print_every}') \n",
    "    \n",
    "    # обучаемся дальше\n",
    "    for i in range((num_iterations - print_every)//print_every):\n",
    "        model = xgb.train(params, train_set,\n",
    "                          num_boost_round=print_every,\n",
    "                          xgb_model=model_file)\n",
    "        model.save_model(model_file)\n",
    "        prediction = model.predict(val)\n",
    "        prediction = np.round(np.clip(prediction, 0, 10)).astype(int)\n",
    "        score = f1_score(y_valid, prediction, average = 'macro')\n",
    "        print(datetime.now().strftime('%Y-%m-%d %H:%M:%S'), ';', \n",
    "              f'score = {score}', ';', f'iter = {(i+2)*print_every}')\n",
    "                      \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кросс валидация с возвращением scores, oof предсказаний и предсказаний на тесте на каждом шаге"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_cv_loop(X_train, y_train, X_test, params, num_iterations):\n",
    "    n_fold = 5\n",
    "    folds = KFold(n_splits=n_fold, shuffle=True, random_state=17)\n",
    "    \n",
    "    oof = np.zeros(X_train.shape[0])\n",
    "    prediction = np.zeros(X_test.shape[0])\n",
    "    scores = []\n",
    "    \n",
    "    for training_index, validation_index in tqdm_notebook(folds.split(X_train), total=n_fold):\n",
    "        # разбиение на трэйн и валидацию\n",
    "        X_train_ = X_train.iloc[training_index].values\n",
    "        y_train_ = y_train[training_index]\n",
    "        X_valid = X_train.iloc[validation_index].values\n",
    "        y_valid = y_train[validation_index]\n",
    "        \n",
    "        # обучение модели\n",
    "        train_set = xgb.DMatrix(X_train_, y_train_)\n",
    "        del X_train_, y_train_\n",
    "        model = xgb.train(params, train_set, num_iterations)\n",
    "\n",
    "        # скор на валидации\n",
    "        X_val_ = xgb.DMatrix(X_valid)\n",
    "        del X_valid\n",
    "        preds = model.predict(X_val_)\n",
    "        oof[validation_index] = preds.reshape(-1,)\n",
    "        preds = np.round(np.clip(preds, 0, 10)).astype(int)\n",
    "        score = f1_score(y_valid, preds, average = 'macro')\n",
    "        scores.append(score)\n",
    "        \n",
    "        # предсказание на тесте\n",
    "        X_test_ = xgb.DMatrix(X_test)\n",
    "        preds = model.predict(X_test_)\n",
    "        prediction += preds\n",
    "        \n",
    "        print(f'score: {score}')\n",
    "        \n",
    "    prediction /= n_fold\n",
    "    prediction = np.round(np.clip(prediction, 0, 10)).astype(int)\n",
    "    \n",
    "    return scores, oof, prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение на трэйне, предсказания на тесте и загрузка предсказаний в файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_final_fit(X_train, y_train, X_test, params, num_iterations,\n",
    "                  filename):\n",
    "    train_set = xgb.DMatrix(X_train, y_train)\n",
    "    \n",
    "    model = xgb.train(params, train_set,\n",
    "                      num_boost_round=num_iterations)\n",
    "    \n",
    "    X_test_ = xgb.DMatrix(X_test)\n",
    "    preds = model.predict(X_test_)\n",
    "    preds = np.round(np.clip(preds, 0, 10)).astype(int)\n",
    "    \n",
    "    sample_df = pd.read_csv(\"data/sample_submission.csv\", dtype={'time':str})\n",
    "    sample_df['open_channels'] = preds\n",
    "    sample_df.to_csv(filename, index=False, float_format='%.4f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интуитивно подобранные параметры. Просто посмотрим, на какие результаты можно рассчитывать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'colsample_bytree': 0.375,\n",
    "          'learning_rate': 0.1,\n",
    "          'max_depth': 15, \n",
    "          'subsample': 0.6, \n",
    "          'objective':'reg:squarederror',\n",
    "          'random_state': 17,\n",
    "          'sample_fraction': 0.3,\n",
    "          #'disable_default_eval_metric': 1,\n",
    "          #'feval': MacroF1Metric,\n",
    "          #'silent': False,\n",
    "          'verbosity': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitting...\n",
      "xgb matrix...\n",
      "2020-04-22 20:58:48 training...\n",
      "2020-04-22 21:05:00 ;  score = 0.2514853229113489\n",
      "2020-04-22 21:11:05 ;  score = 0.9066280718838962\n",
      "2020-04-22 21:18:04 ;  score = 0.9356554089896456\n",
      "2020-04-22 21:23:54 ;  score = 0.9364960805419013\n",
      "2020-04-22 21:29:53 ;  score = 0.9366241019441741\n",
      "2020-04-22 21:35:53 ;  score = 0.9366606590319936\n",
      "2020-04-22 21:42:00 ;  score = 0.9365105940507171\n",
      "2020-04-22 21:48:08 ;  score = 0.9363963739454916\n",
      "2020-04-22 21:54:13 ;  score = 0.9365528560911008\n",
      "2020-04-22 22:00:25 ;  score = 0.9365558127127536\n"
     ]
    }
   ],
   "source": [
    "num_iterations = 150\n",
    "model_file = 'baseline'\n",
    "model = fit_model_with_save(X_train, y_train, params, num_iterations,\n",
    "                            model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:58:39] WARNING: src/learner.cc:686: Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\n"
     ]
    }
   ],
   "source": [
    "xgb_final_fit(X_train, y_train, X_test, params, 180,\n",
    "              'xgb1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Результат:** 0.74 на public lb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Подбор гиперпараметров\n",
    "\n",
    "Кросс-валидацию делать не будем, потому что это занимает ну ооочень много времени"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1)** Выставляем lr = 0.1 и подбираем оптимальное кол-во базовых моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'colsample_bytree': 0.8,\n",
    "          'subsample': 0.8,\n",
    "          'min_child_weight': 1,\n",
    "          'gamma': 0,\n",
    "          'learning_rate': 0.1,\n",
    "          'max_depth': 5,  \n",
    "          'objective':'reg:squarederror',\n",
    "          'random_state': 17,\n",
    "          'scale_pos_weight': 1,\n",
    "          #'sample_fraction': 0.3,\n",
    "          #'disable_default_eval_metric': 1,\n",
    "          #'feval': MacroF1Metric,\n",
    "          #'silent': False,\n",
    "          'verbosity': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitting...\n",
      "xgb matrix...\n",
      "2020-04-23 14:15:02 training...\n",
      "2020-04-23 14:18:49 ;  score = 0.2554834467327609\n",
      "2020-04-23 14:22:15 ;  score = 0.8963421300196369\n",
      "2020-04-23 14:25:33 ;  score = 0.9321451392206783\n",
      "2020-04-23 14:29:07 ;  score = 0.9338145896679587\n",
      "2020-04-23 14:32:23 ;  score = 0.934131460133078\n",
      "2020-04-23 14:35:38 ;  score = 0.9346158157227461\n",
      "2020-04-23 14:38:49 ;  score = 0.9348994447464274\n",
      "2020-04-23 14:42:17 ;  score = 0.935092895363558\n",
      "2020-04-23 14:45:40 ;  score = 0.9352733770589446\n",
      "2020-04-23 14:48:59 ;  score = 0.9353673372153349\n",
      "2020-04-23 14:52:16 ;  score = 0.9354925468736269\n",
      "2020-04-23 14:55:33 ;  score = 0.9355846320619841\n",
      "2020-04-23 14:58:53 ;  score = 0.9356856854618399\n",
      "2020-04-23 15:02:09 ;  score = 0.9357058751648332\n",
      "2020-04-23 15:05:21 ;  score = 0.935755781712166\n",
      "2020-04-23 15:08:51 ;  score = 0.9357435761580665\n"
     ]
    }
   ],
   "source": [
    "num_iterations = 240\n",
    "model_file = 'xgb2'\n",
    "model = fit_model_with_save(X_train, y_train, params, num_iterations,\n",
    "                            model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После 210 итераций скор перестал расти, но пока оставим с запасом 240"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2)** фиксируем оптимальное кол-во базовых моделей и подбираем max_depth и min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "289"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitting...\n",
      "xgb matrix...\n",
      "2020-04-23 15:20:04 training...\n",
      "2020-04-23 15:25:23 ;  score = 0.25006823742430356\n",
      "2020-04-23 15:30:26 ;  score = 0.912823272810611\n",
      "2020-04-23 15:35:33 ;  score = 0.9368060153883081\n",
      "2020-04-23 15:41:11 ;  score = 0.9374241853801102\n",
      "2020-04-23 15:46:24 ;  score = 0.9374653167767765\n",
      "2020-04-23 15:51:40 ;  score = 0.9375196402162413\n",
      "2020-04-23 15:56:51 ;  score = 0.937549552978194\n",
      "2020-04-23 16:02:51 ;  score = 0.9375587758492795\n",
      "2020-04-23 16:08:21 ;  score = 0.9375751008459111\n",
      "2020-04-23 16:14:23 ;  score = 0.9376111089557089\n",
      "2020-04-23 16:19:57 ;  score = 0.9376400798505671\n",
      "2020-04-23 16:25:44 ;  score = 0.9376723901809817\n",
      "2020-04-23 16:31:15 ;  score = 0.9376656160130431\n",
      "2020-04-23 16:36:44 ;  score = 0.9376754383874787\n",
      "2020-04-23 16:42:24 ;  score = 0.9376577086764635\n",
      "2020-04-23 16:47:44 ;  score = 0.9376625218435387\n"
     ]
    }
   ],
   "source": [
    "params = {'colsample_bytree': 0.8,\n",
    "          'subsample': 0.8,\n",
    "          'min_child_weight': 1,\n",
    "          'gamma': 0,\n",
    "          'learning_rate': 0.1,\n",
    "          'max_depth': 8,  \n",
    "          'objective':'reg:squarederror',\n",
    "          'random_state': 17,\n",
    "          'scale_pos_weight': 1,\n",
    "          #'sample_fraction': 0.3,\n",
    "          #'disable_default_eval_metric': 1,\n",
    "          #'feval': MacroF1Metric,\n",
    "          #'silent': False,\n",
    "          'verbosity': 1}\n",
    "\n",
    "num_iterations = 240\n",
    "model_file = 'xgb2'\n",
    "model = fit_model_with_save(X_train, y_train, params, num_iterations,\n",
    "                            model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitting...\n",
      "xgb matrix...\n",
      "2020-04-23 17:20:59 training...\n",
      "2020-04-23 17:27:58 ;  score = 0.2503194481649376\n",
      "2020-04-23 17:35:02 ;  score = 0.9138654867752734\n",
      "2020-04-23 17:42:26 ;  score = 0.9368336956019466\n",
      "2020-04-23 17:49:23 ;  score = 0.9374082400604258\n",
      "2020-04-23 17:56:15 ;  score = 0.9374970812672777\n",
      "2020-04-23 18:03:17 ;  score = 0.9375623214346437\n",
      "2020-04-23 18:11:00 ;  score = 0.9376161451657743\n",
      "2020-04-23 18:18:07 ;  score = 0.9375875117333036\n",
      "2020-04-23 18:25:03 ;  score = 0.937709455140595\n",
      "2020-04-23 18:32:24 ;  score = 0.9377068554739886\n",
      "2020-04-23 18:40:21 ;  score = 0.9376544036216959\n",
      "2020-04-23 18:49:05 ;  score = 0.9377614891878415\n",
      "2020-04-23 18:57:37 ;  score = 0.9377882780678884\n",
      "2020-04-23 19:06:52 ;  score = 0.9377616578276331\n",
      "2020-04-23 19:15:58 ;  score = 0.9377937239329167\n",
      "2020-04-23 19:24:42 ;  score = 0.9376539733991446\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "\n",
    "params = {'colsample_bytree': 0.8,\n",
    "          'subsample': 0.8,\n",
    "          'min_child_weight': 1,\n",
    "          'gamma': 0,\n",
    "          'learning_rate': 0.1,\n",
    "          'max_depth': 10,  \n",
    "          'objective':'reg:squarederror',\n",
    "          'random_state': 17,\n",
    "          'scale_pos_weight': 1,\n",
    "          #'sample_fraction': 0.3,\n",
    "          #'disable_default_eval_metric': 1,\n",
    "          #'feval': MacroF1Metric,\n",
    "          #'silent': False,\n",
    "          'verbosity': 1}\n",
    "\n",
    "num_iterations = 240\n",
    "model_file = 'xgb2'\n",
    "model = fit_model_with_save(X_train, y_train, params, num_iterations,\n",
    "                            model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitting...\n",
      "xgb matrix...\n",
      "2020-04-23 19:37:22 training...\n",
      "2020-04-23 19:46:14 ;  score = 0.2501612177044458\n",
      "2020-04-23 19:53:51 ;  score = 0.9137808478451652\n",
      "2020-04-23 20:01:58 ;  score = 0.9370674609513882\n",
      "2020-04-23 20:10:09 ;  score = 0.937498926185457\n",
      "2020-04-23 20:18:06 ;  score = 0.9375460114532341\n",
      "2020-04-23 20:25:55 ;  score = 0.937623676348955\n",
      "2020-04-23 20:33:53 ;  score = 0.9376627121558919\n",
      "2020-04-23 20:41:24 ;  score = 0.9376842206643093\n",
      "2020-04-23 20:48:21 ;  score = 0.9376003658310953\n",
      "2020-04-23 20:55:16 ;  score = 0.9376562714149107\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "\n",
    "params = {'colsample_bytree': 0.8,\n",
    "          'subsample': 0.8,\n",
    "          'min_child_weight': 3,\n",
    "          'gamma': 0,\n",
    "          'learning_rate': 0.1,\n",
    "          'max_depth': 10,  \n",
    "          'objective':'reg:squarederror',\n",
    "          'random_state': 17,\n",
    "          'scale_pos_weight': 1,\n",
    "          #'sample_fraction': 0.3,\n",
    "          #'disable_default_eval_metric': 1,\n",
    "          #'feval': MacroF1Metric,\n",
    "          #'silent': False,\n",
    "          'verbosity': 1}\n",
    "\n",
    "num_iterations = 150\n",
    "model_file = 'xgb2'\n",
    "model = fit_model_with_save(X_train, y_train, params, num_iterations,\n",
    "                            model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3)** подбираем gamma "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitting...\n",
      "xgb matrix...\n",
      "2020-04-23 20:57:16 training...\n",
      "2020-04-23 21:04:06 ;  score = 0.2506296987539088 ; iter = 15\n",
      "2020-04-23 21:10:48 ; score = 0.9139050347991468 ; iter = 30\n",
      "2020-04-23 21:17:27 ; score = 0.9370139031734332 ; iter = 45\n",
      "2020-04-23 21:24:29 ; score = 0.9374695295735728 ; iter = 60\n",
      "2020-04-23 21:31:45 ; score = 0.9375796895269083 ; iter = 75\n",
      "2020-04-23 21:39:00 ; score = 0.9376779571769867 ; iter = 90\n",
      "2020-04-23 21:46:19 ; score = 0.9376490541078816 ; iter = 105\n",
      "2020-04-23 21:53:46 ; score = 0.9376201510755025 ; iter = 120\n",
      "2020-04-23 22:01:20 ; score = 0.9376784071296256 ; iter = 135\n",
      "2020-04-23 22:08:46 ; score = 0.9376747032184686 ; iter = 150\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "\n",
    "params = {'colsample_bytree': 0.8,\n",
    "          'subsample': 0.8,\n",
    "          'min_child_weight': 1,\n",
    "          'gamma': 0.2,\n",
    "          'learning_rate': 0.1,\n",
    "          'max_depth': 10,  \n",
    "          'objective':'reg:squarederror',\n",
    "          'random_state': 17,\n",
    "          'scale_pos_weight': 1,\n",
    "          #'sample_fraction': 0.3,\n",
    "          #'disable_default_eval_metric': 1,\n",
    "          #'feval': MacroF1Metric,\n",
    "          #'silent': False,\n",
    "          'verbosity': 1}\n",
    "\n",
    "num_iterations = 150\n",
    "model_file = 'xgb2'\n",
    "model = fit_model_with_save(X_train, y_train, params, num_iterations,\n",
    "                            model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4)** подбираем subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitting...\n",
      "xgb matrix...\n",
      "2020-04-24 00:07:20 training...\n",
      "2020-04-24 00:13:41 ;  score = 0.25081748530214587 ; iter = 15\n",
      "2020-04-24 00:19:38 ; score = 0.9126555502112467 ; iter = 30\n",
      "2020-04-24 00:25:45 ; score = 0.9367373146138956 ; iter = 45\n",
      "2020-04-24 00:31:37 ; score = 0.9373653116171698 ; iter = 60\n",
      "2020-04-24 00:37:23 ; score = 0.9375435578604457 ; iter = 75\n",
      "2020-04-24 00:42:55 ; score = 0.937601320170155 ; iter = 90\n",
      "2020-04-24 00:48:43 ; score = 0.9376592288963951 ; iter = 105\n",
      "2020-04-24 00:54:26 ; score = 0.9376345979531446 ; iter = 120\n",
      "2020-04-24 01:00:16 ; score = 0.9376077333855745 ; iter = 135\n",
      "2020-04-24 01:05:49 ; score = 0.9376453293658905 ; iter = 150\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "\n",
    "params = {'colsample_bytree': 0.6,\n",
    "          'subsample': 0.6,\n",
    "          'min_child_weight': 1,\n",
    "          'gamma': 0,\n",
    "          'learning_rate': 0.1,\n",
    "          'max_depth': 10,  \n",
    "          'objective':'reg:squarederror',\n",
    "          'random_state': 17,\n",
    "          'scale_pos_weight': 1,\n",
    "          #'sample_fraction': 0.3,\n",
    "          #'disable_default_eval_metric': 1,\n",
    "          #'feval': MacroF1Metric,\n",
    "          #'silent': False,\n",
    "          'verbosity': 1}\n",
    "\n",
    "num_iterations = 150\n",
    "model_file = 'xgb2'\n",
    "model = fit_model_with_save(X_train, y_train, params, num_iterations,\n",
    "                            model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitting...\n",
      "xgb matrix...\n",
      "2020-04-24 01:13:25 training...\n",
      "2020-04-24 01:22:30 ;  score = 0.251063064380594 ; iter = 15\n",
      "2020-04-24 01:31:43 ; score = 0.9159318612995222 ; iter = 30\n",
      "2020-04-24 01:40:56 ; score = 0.9370485494045749 ; iter = 45\n",
      "2020-04-24 01:50:29 ; score = 0.9377247401053093 ; iter = 60\n",
      "2020-04-24 01:58:55 ; score = 0.9377206048084582 ; iter = 75\n",
      "2020-04-24 02:08:30 ; score = 0.937720093571756 ; iter = 90\n",
      "2020-04-24 10:32:37 ; score = 0.93776339305632 ; iter = 105\n",
      "2020-04-24 10:42:21 ; score = 0.9378310238524001 ; iter = 120\n",
      "2020-04-24 10:51:42 ; score = 0.9378398147773944 ; iter = 135\n",
      "2020-04-24 11:01:32 ; score = 0.9378258351411914 ; iter = 150\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "\n",
    "params = {'colsample_bytree': 1.,\n",
    "          'subsample': 1.,\n",
    "          'min_child_weight': 1,\n",
    "          'gamma': 0,\n",
    "          'learning_rate': 0.1,\n",
    "          'max_depth': 10,  \n",
    "          'objective':'reg:squarederror',\n",
    "          'random_state': 17,\n",
    "          'scale_pos_weight': 1,\n",
    "          #'sample_fraction': 0.3,\n",
    "          #'disable_default_eval_metric': 1,\n",
    "          #'feval': MacroF1Metric,\n",
    "          #'silent': False,\n",
    "          'verbosity': 1}\n",
    "\n",
    "num_iterations = 150\n",
    "model_file = 'xgb2'\n",
    "model = fit_model_with_save(X_train, y_train, params, num_iterations,\n",
    "                            model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5)** подбираем регуляризацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitting...\n",
      "xgb matrix...\n",
      "2020-04-24 11:49:19 training...\n",
      "2020-04-24 11:59:58 ;  score = 0.25146122830402234 ; iter = 15\n",
      "2020-04-24 12:10:07 ; score = 0.9163313544606223 ; iter = 30\n",
      "2020-04-24 12:20:56 ; score = 0.9370002102709702 ; iter = 45\n",
      "2020-04-24 12:31:31 ; score = 0.9375705060204939 ; iter = 60\n",
      "2020-04-24 12:42:07 ; score = 0.9376683673301709 ; iter = 75\n",
      "2020-04-24 12:51:46 ; score = 0.9376570803333721 ; iter = 90\n",
      "2020-04-24 14:16:31 ; score = 0.9376869417562399 ; iter = 105\n",
      "2020-04-24 14:26:30 ; score = 0.9376398873257444 ; iter = 120\n",
      "2020-04-24 14:35:58 ; score = 0.9377006404643846 ; iter = 135\n",
      "2020-04-24 14:45:30 ; score = 0.9377315938085657 ; iter = 150\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "\n",
    "params = {'colsample_bytree': 1.,\n",
    "          'subsample': 1.,\n",
    "          'min_child_weight': 1,\n",
    "          'gamma': 0,\n",
    "          'learning_rate': 0.1,\n",
    "          'max_depth': 10,  \n",
    "          'objective':'reg:squarederror',\n",
    "          'random_state': 17,\n",
    "          'scale_pos_weight': 1,\n",
    "          'reg_alpha': 0.05,\n",
    "          #'sample_fraction': 0.3,\n",
    "          #'disable_default_eval_metric': 1,\n",
    "          #'feval': MacroF1Metric,\n",
    "          #'silent': False,\n",
    "          'verbosity': 1}\n",
    "\n",
    "num_iterations = 150\n",
    "model_file = 'xgb2'\n",
    "model = fit_model_with_save(X_train, y_train, params, num_iterations,\n",
    "                            model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6)** уменьшаем lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitting...\n",
      "xgb matrix...\n",
      "2020-04-24 14:47:23 training...\n",
      "2020-04-24 14:56:34 ;  score = 0.16272613132626346 ; iter = 15\n",
      "2020-04-24 15:05:05 ; score = 0.24746736608246309 ; iter = 30\n",
      "2020-04-24 15:13:13 ; score = 0.5617137717322215 ; iter = 45\n",
      "2020-04-24 15:22:04 ; score = 0.9079213359533269 ; iter = 60\n",
      "2020-04-24 15:31:50 ; score = 0.9338825748073436 ; iter = 75\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "\n",
    "params = {'colsample_bytree': 1.,\n",
    "          'subsample': 1.,\n",
    "          'min_child_weight': 1,\n",
    "          'gamma': 0,\n",
    "          'learning_rate': 0.05,\n",
    "          'max_depth': 10,  \n",
    "          'objective':'reg:squarederror',\n",
    "          'random_state': 17,\n",
    "          'scale_pos_weight': 1,\n",
    "          #'sample_fraction': 0.3,\n",
    "          #'disable_default_eval_metric': 1,\n",
    "          #'feval': MacroF1Metric,\n",
    "          #'silent': False,\n",
    "          'verbosity': 1}\n",
    "\n",
    "num_iterations = 210\n",
    "model_file = 'xgb2'\n",
    "model = fit_model_with_save(X_train, y_train, params, num_iterations,\n",
    "                            model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Финальные предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "\n",
    "params = {'colsample_bytree': 1.,\n",
    "          'subsample': 1.,\n",
    "          'min_child_weight': 1,\n",
    "          'gamma': 0,\n",
    "          'learning_rate': 0.05,\n",
    "          'max_depth': 10,  \n",
    "          'objective':'reg:squarederror',\n",
    "          'random_state': 17,\n",
    "          'scale_pos_weight': 1,\n",
    "          #'sample_fraction': 0.3,\n",
    "          #'disable_default_eval_metric': 1,\n",
    "          #'feval': MacroF1Metric,\n",
    "          #'silent': False,\n",
    "          'verbosity': 1}\n",
    "\n",
    "num_iterations = 210\n",
    "model_file = 'xgb3'\n",
    "xgb_final_fit(X_train, y_train, X_test, params, num_iterations, model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Результат:** 0.84 на public lb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
